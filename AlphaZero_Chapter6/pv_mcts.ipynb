{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pv_mcts.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNmaxSEU7mylJC1nSz6sywg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"YKXImtQHcXX4","colab_type":"code","outputId":"9fb6bf9a-1e14-4d9a-ca7b-4ce794035b5d","executionInfo":{"status":"error","timestamp":1592282881136,"user_tz":-540,"elapsed":800,"user":{"displayName":"つかさ/ TSUKASA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZvQXbXBaNshsEvWGFCNb8oZJJ1DxSJ9xmMS0B=s64","userId":"06291802442640135710"}},"colab":{"base_uri":"https://localhost:8080/","height":368}},"source":["# パッケージ のインポート\n","from game import  State\n","from dual_network import DN_INPUT_SHAPE\n","from math import sqrt\n","from tensorflow.keras.models import load_model\n","from pathlib import Path\n","import numpy as np"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0ce6d8353770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# パッケージ のインポート\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdual_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDN_INPUT_SHAPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'game'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"XID6EHVgdICH","colab_type":"code","colab":{}},"source":["# パラメータの準備\n","PV_EVALUATE_COUNT = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XxQk9lpeJOO","colab_type":"code","colab":{}},"source":["# 推論\n","def predict(model, state):\n","    # 推論のための入力データのシェイプの変換\n","    a, b, c = DN_INPUT_SHAPE # (3,3,2)\n","    x = np.array([state.pieces, state.enemy_pieces])\n","    x = x.reshape(c, a, b).transpose(1,2,0).reshape(1, a, b, c) # シェイプ(1, 3, 3, 2)\n","\n","    # 推論\n","    y = model.predict(x, batch_size=1)\n","\n","    # 方策の取得\n","    policies = y[0][0][list(state.legal_actions())] # 合法手のみ\n","    policies /= sum(policies) if sum(policies) else 1 # 合計１の確率分布に変換\n","\n","    #価値の取得\n","    value = y[1][0][0]\n","    \n","    return policies, value"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxQKlDTEl2gK","colab_type":"code","colab":{}},"source":["# ノードのリストを試行回数のリストに変換\n","def nodes_to_scores(nodes):\n","    scores = []\n","    for c in nodes:\n","        scores.append(c.n)\n","    return scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HhQ_bzcimXlU","colab_type":"code","colab":{}},"source":["# モンテカルロ木探索のスコアの取得\n","def pv_mcts_scores(model, state, temperature):\n","    # モンテカルロ木探索のノードの定義\n","    class node:\n","        # ノードの初期化\n","        def __init__(self, state, p):\n","            self.state = state # 状態\n","            self.p = p # 方策\n","            self.w = 0 # 累計価値\n","            self.n = 0 # 試行回数\n","            self.child_nodes = None # 子ノード群\n","\n","        # 局面の評価\n","        def evaluate(self):\n","            if self.state.is_done():\n","                # 勝敗結果で価値を取得\n","                value = -1 if self.state.is_lose() else 0\n","\n","                # 累計価値と試行回数の更新\n","                self.w += value\n","                self.n += 1\n","                return value\n","\n","            # ゲーム終了時以外で子ノードが存在しない時\n","            if not self.child_nodes:\n","                # ニューラルネットワーくの推論で方策と価値を取得\n","                policies, value = predict(model, self.state)\n","\n","                # 累計価値と試行回数の更新\n","                self.w += value\n","                self.n += 1\n","\n","                # 子ノードの展開\n","                self.child_nodes = []\n","                for action, policy in zip(self.state.legal_actions(), policies):\n","                    self.child_nodes.append(node(self.state.next(action), policy))\n","\n","                return value\n","\n","            # 子ノードが存在する時\n","            else:\n","                # アークの評価値が最大の子ノードの評価で価値を取得\n","                value = self.next_child_node().evaluate()\n","\n","                # 累計価値と試行回数の更新\n","                self.w += value\n","                self.n += 1\n","                return value\n","\n","        # アーク評価値が最大の子ノードの取得\n","        def next_child_node(self):\n","            C_PUCT = 1.0 # 「勝率」と「手の予測確率　* バイアス」のバランスを調整するために定数\n","            t = sum(nodes_to_scores(self.child_nodes))\n","            pucb_values = []\n","            for c in self.child_nodes:\n","                pucb_values.append((-c.w / c.n if c.n else 0.0) + C_PUCT * c.p * sqrt(t) / (1 + c.n))\n","        \n","            # アーク評価値が最大の子ノードを返す\n","            return self.child_nodes[np.argmax(pucb_values)]\n","\n","    # 現在の局面のノードの作成\n","    root_node = node(state, 0)\n","\n","    # 複数回の評価の実行\n","    for _ in range(PV_EVALUATE_COUNT):\n","        root_node.evaluate()\n","\n","    # 合法手の確率分布\n","    scores = nodes_to_scores(root_node.child_nodes)\n","    if temperature == 0: # 試行回数が最大値のスコアのみ１、それ以外は全て０\n","        action = np.argmax(scores)\n","        scores = np.zeros(len(scores))\n","        scores[action] = 1\n","    else: # ボルツマン分布でばらつき付加\n","        scores = boltzman(scores, temperature)\n","    \n","    return scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-u2am1qPw7XO","colab_type":"code","colab":{}},"source":["# モンテカルロ木探索で行動選択\n","def pv_mcts_action(model, temperature=0):\n","    def pv_mcts_action(state):\n","        scores = pv_mcts_scores(model, state, temperature)\n","        return np.random.choice(state.legal_actions(), p=scores)\n","    # 関数の中の関数の返り値を返す\n","    return pv_mcts_action"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OYNHlpowymny","colab_type":"code","colab":{}},"source":["# ボルツマン分布\n","def boltzman(xs, temperature):\n","    xs = [x ** (1 / temperature) for x in xs]\n","    return [x / sum(xs) for x in xs]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aCngTUQLzV-k","colab_type":"code","colab":{}},"source":["# 動作確認\n","if __name__ == '__main__':\n","    # モデル読み込み\n","    path = sorted(Path('./model').glob('*.h5'))[-1]\n","    model = load_model(str(path))\n","\n","    # 状態の生成\n","    state = State()\n","\n","    # モンテカルロ木探索で行動選択を行う関数の生成\n","    next_action = pv_mcts_action(model, 1.0)\n","\n","    # ゲーム終了までループ\n","    while True:\n","        if state.is_done():\n","            break\n","\n","        action = next_action(state)\n","\n","        state = state.next(action)\n","\n","        print(state)"],"execution_count":0,"outputs":[]}]}