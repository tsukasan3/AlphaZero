{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"self_play.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbSUcNWPB0Bg6astyTtzK+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"JQQAXVnHveEh","colab_type":"code","colab":{}},"source":["# パッケージ のインポート\n","from game import State\n","from pv_mcts import pv_mcts_scores\n","from dual_network import DN_OUTPUT_SIZE\n","from datetime import datetime\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras import backend as K\n","from pathlib import Path\n","import numpy as np\n","import pickle\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwZzmnV8wnvx","colab_type":"code","colab":{}},"source":["# パラメータの準備\n","SP_GAME_COUNT = 500 # セルフプレイを行うゲーム数\n","SP_TEMPERATURE = 1.0 # ボルツマン分布の温度パラメータ"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDsn3MLPxYHF","colab_type":"code","colab":{}},"source":["# 先手プレイヤーの価値\n","def first_player_value(ended_state):\n","    # １：先手かち、−１：先手負け、０：引き分け\n","    if ended_state.is_lose():\n","        return -1 if ended_state.is_first_player() else 1\n","    return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"klj1oeKeyAeL","colab_type":"code","colab":{}},"source":["# 学習データの保存\n","def write_data(history):\n","    now = datetime.now()\n","    os.makedirs('./data/', exist_ok=True) # フォルダがない時は生成\n","    path = './data/{:04}{:02}{:02}{:02}{:02}{:02}.history'.format(\n","        now.year, now.month, now.day, now.hour, now.minute, now.second\n","    )\n","    with open(path, mode='wb') as f:\n","        pickle.dump(history, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S06kRnxszg6j","colab_type":"code","colab":{}},"source":["# 1ゲームの実行\n","def play(model):\n","    # 学習データ\n","    history = []\n","\n","    # 状態の生成\n","    state = State()\n","\n","    while True:\n","        # ゲーム終了時\n","        if state.is_done():\n","            break\n","\n","        # 合法手の確率分布の取得\n","        scores = pv_mcts_scores(model, state, SP_TEMPERATURE)\n","\n","        # 学習データに状態と方策を追加\n","        policies = [0] * DN_OUTPUT_SIZE # =9\n","        for action, policy in zip(state.legal_actions(), scores):\n","            policies[action] = policy\n","        history.append([[state.pieces, state.enemy_pieces], policies, None])\n","\n","        # 行動の取得\n","        action = np.random.choice(state.legal_actions(), p=scores)\n","\n","        # 次の状態の取得\n","        state = state.next(action)\n","\n","    # 学習データに価値を追加\n","    value = first_player_value(state)\n","    for i in range(len(history)):\n","        history[i][2] = value\n","        value = -value # 後半プレイヤーの価値は符号が逆になる\n","    return history \n","\n","# セルフプレイ\n","def self_play():\n","    # 学習データ\n","    history = []\n","\n","    # ベストプレイヤーのモデルの読み込み\n","    model = load_model('./model/best.h5')\n","\n","    # 複数回のゲームの実行\n","    for i in range(SP_GAME_COUNT):\n","        # 1ゲームの実行\n","        h = play(model)\n","        history.extend(h)\n","\n","        # 出力\n","        print('\\rSelfPlay {}/{}'.format(i+1, SP_GAME_COUNT), end='')\n","    print('')\n","\n","    # 学習データの保存\n","    write_data(history)\n","\n","    # モデルの破棄\n","    K.clear_session()\n","    del model\n","\n","# 動作確認\n","if __name__ == '__main__':\n","    self_play()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHWZm5Sk3G5T","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}